{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8IRTu-ZZSveQ",
    "outputId": "f2e1d190-8b52-4c37-f800-cff3ffe64ad5"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.ticker as ticker\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vY5i1AziSvg0",
    "outputId": "e7b65493-c707-41a0-d6d7-bef785e650d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu129\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uMnybQWSvi7",
    "outputId": "d1975a92-2417-4a73-8957-d57563293a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 디렉토리: ['_about.txt', 'kor-eng.zip', 'kor.txt']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "LANG_PAIR = \"kor-eng\"\n",
    "DATA_FILE = \"kor.txt\"\n",
    "DATASET_URL = \"https://www.manythings.org/anki/kor-eng.zip\"\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules or Path(\"/content\").exists()\n",
    "if IN_COLAB:\n",
    "    base_dir = Path(\"/content/drive/MyDrive/AIFFEL/Deep_Dive/work/s2s_translation/datasets\")\n",
    "else:\n",
    "    base_dir = Path.cwd() / \"datasets\"\n",
    "base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset_dir = base_dir / LANG_PAIR\n",
    "dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "zip_path = dataset_dir / f\"{LANG_PAIR}.zip\"\n",
    "if not zip_path.exists():\n",
    "    local_zip_candidates = [\n",
    "        Path.cwd() / f\"{LANG_PAIR}.zip\",\n",
    "        Path.cwd() / \"20251121\" / f\"{LANG_PAIR}.zip\"\n",
    "    ]\n",
    "    copied = False\n",
    "    for candidate in local_zip_candidates:\n",
    "        if candidate.exists():\n",
    "            shutil.copy(candidate, zip_path)\n",
    "            print(f\"로컬에 있던 {candidate.name}을(를) 재사용합니다.\")\n",
    "            copied = True\n",
    "            break\n",
    "    if not copied:\n",
    "        print(\"데이터 다운로드 중...\")\n",
    "        urllib.request.urlretrieve(DATASET_URL, str(zip_path))\n",
    "        print(\"다운로드 완료!\")\n",
    "\n",
    "path_to_file = dataset_dir / DATA_FILE\n",
    "if not path_to_file.exists():\n",
    "    print(\"압축 해제 중...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(dataset_dir)\n",
    "    print(\"압축 해제 완료!\")\n",
    "\n",
    "print(\"데이터셋 디렉토리:\", sorted(p.name for p in dataset_dir.iterdir()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iozU2l0USvlM",
    "outputId": "612ebab2-9d8d-4b97-bcef-9c6a9fb2b729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 문장 쌍 수: 6,381\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>kor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>가.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>안녕.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>뛰어!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run.</td>\n",
       "      <td>뛰어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>누구?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng  kor\n",
       "0   Go.   가.\n",
       "1   Hi.  안녕.\n",
       "2  Run!  뛰어!\n",
       "3  Run.  뛰어.\n",
       "4  Who?  누구?"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"eng\", \"kor\", \"attribution\"]\n",
    "df = (\n",
    "    pd.read_csv(\n",
    "        path_to_file,\n",
    "        sep=\"\t\",\n",
    "        names=column_names,\n",
    "        quoting=3,\n",
    "        engine=\"python\"\n",
    "    )\n",
    "    .drop(columns=[\"attribution\"])\n",
    ")\n",
    "df = df.dropna(subset=[\"eng\", \"kor\"]).reset_index(drop=True)\n",
    "print(f\"총 문장 쌍 수: {len(df):,}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_f4ksnhZSvnI",
    "outputId": "bd493f60-f92a-4bd3-ce63-ca6235a0dc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    영어/한국어 문장 전처리: 소문자화, 구두점 정규화, 특수문자 제거 등\n",
    "    (구체적 토큰화는 SentencePiece에서 수행)\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'([.!?,])\\1+', r'\\1', text)\n",
    "    text = re.sub(r\"[^가-힣a-zA-Z0-9\\s.!?,']\", \" \", text)\n",
    "    text = re.sub(r'([.!?,])', r' \\1 ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "preprocess_korean = preprocess_text\n",
    "\n",
    "print(\"슝~\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sbkmjXFxSvpO",
    "outputId": "7ed4afda-e166-4020-9a10-9b7811b95a66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장부호 제거 기준 중복 문장 수: 689건\n",
      "영문 1문장에 대해 다수의 한국어 번역을 가진 문장 수: 601건 (baseline 유지)\n",
      "시퀀스 길이 통계:        eng_len  kor_len\n",
      "count  6381.00  6381.00\n",
      "mean      6.57     5.24\n",
      "std       2.94     2.27\n",
      "min       2.00     1.00\n",
      "25%       5.00     4.00\n",
      "50%       6.00     5.00\n",
      "75%       8.00     6.00\n",
      "max     110.00    95.00\n",
      "권장 max_len: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>kor</th>\n",
       "      <th>eng_proc</th>\n",
       "      <th>kor_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>가.</td>\n",
       "      <td>go .</td>\n",
       "      <td>가 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>안녕.</td>\n",
       "      <td>hi .</td>\n",
       "      <td>안녕 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>뛰어!</td>\n",
       "      <td>run !</td>\n",
       "      <td>뛰어 !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run.</td>\n",
       "      <td>뛰어.</td>\n",
       "      <td>run .</td>\n",
       "      <td>뛰어 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>누구?</td>\n",
       "      <td>who ?</td>\n",
       "      <td>누구 ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng  kor eng_proc kor_proc\n",
       "0   Go.   가.     go .      가 .\n",
       "1   Hi.  안녕.     hi .     안녕 .\n",
       "2  Run!  뛰어!    run !     뛰어 !\n",
       "3  Run.  뛰어.    run .     뛰어 .\n",
       "4  Who?  누구?    who ?     누구 ?"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"eng_proc\"] = df[\"eng\"].apply(preprocess_text)\n",
    "df[\"kor_proc\"] = df[\"kor\"].apply(preprocess_korean)\n",
    "\n",
    "punct_key = df[\"eng_proc\"].str.replace(r\"[.!?',]\", \"\", regex=True).str.strip()\n",
    "punct_dups = punct_key.duplicated().sum()\n",
    "multi_targets = (df.groupby(\"eng_proc\")[\"kor_proc\"].nunique() > 1).sum()\n",
    "\n",
    "lengths = pd.DataFrame({\n",
    "    \"eng_len\": df[\"eng_proc\"].str.split().str.len(),\n",
    "    \"kor_len\": df[\"kor_proc\"].str.split().str.len()\n",
    "})\n",
    "length_summary = lengths.describe().round(2)\n",
    "length_summary.to_csv(\"sequence_length_stats.csv\")\n",
    "\n",
    "recommended_max_len = int(lengths.quantile(0.95).max())\n",
    "MAX_SEQ_LEN = max(25, min(recommended_max_len, 60))\n",
    "\n",
    "print(f\"문장부호 제거 기준 중복 문장 수: {punct_dups:,}건\")\n",
    "print(f\"영문 1문장에 대해 다수의 한국어 번역을 가진 문장 수: {multi_targets:,}건 (baseline 유지)\")\n",
    "print(\"시퀀스 길이 통계:\", length_summary)\n",
    "print(f\"권장 max_len: {MAX_SEQ_LEN}\")\n",
    "\n",
    "df[[\"eng\", \"kor\", \"eng_proc\", \"kor_proc\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jk1nwjuuSvrR",
    "outputId": "6a7cba32-eaea-4294-ac29-8b17415da37d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 저장 완료: eng_corpus.txt, kor_corpus.txt\n"
     ]
    }
   ],
   "source": [
    "df[\"eng_proc\"].to_csv(\"eng_corpus.txt\", index=False, header=False, encoding=\"utf-8\")\n",
    "df[\"kor_proc\"].to_csv(\"kor_corpus.txt\", index=False, header=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"파일 저장 완료: eng_corpus.txt, kor_corpus.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "gc5pnvjTSvtX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_spm: 실제 vocab size = 2396\n",
      "decoder_spm: 실제 vocab size = 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: eng_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: encoder_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 3000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 0\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: eng_corpus.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 6381 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=190774\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9623% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=35\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999623\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 6381 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=112044\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 6038 seed sentencepieces\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 6381\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 3461\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 3461 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2962 obj=9.34092 num_tokens=7112 num_tokens/piece=2.40108\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2390 obj=7.98961 num_tokens=7236 num_tokens/piece=3.02762\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: encoder_spm.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: encoder_spm.vocab\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: kor_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: decoder_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 3000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 0\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: kor_corpus.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 6381 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=110306\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=957\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 6381 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=45363\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 6854 seed sentencepieces\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 6381\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 8588\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 8588 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=4420 obj=10.8781 num_tokens=18714 num_tokens/piece=4.23394\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3930 obj=10.1003 num_tokens=18840 num_tokens/piece=4.79389\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3300 obj=10.6323 num_tokens=19884 num_tokens/piece=6.02545\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3299 obj=10.5901 num_tokens=19917 num_tokens/piece=6.03728\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: decoder_spm.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: decoder_spm.vocab\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 3000\n",
    "pad_id = 0\n",
    "bos_id = 1\n",
    "eos_id = 2\n",
    "unk_id = 3\n",
    "\n",
    "\n",
    "def train_sentencepiece(input_file, model_prefix, vocab_size):\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=input_file,\n",
    "        model_prefix=model_prefix,\n",
    "        vocab_size=vocab_size,\n",
    "        pad_id=pad_id,\n",
    "        bos_id=bos_id,\n",
    "        eos_id=eos_id,\n",
    "        unk_id=unk_id,\n",
    "        hard_vocab_limit=False\n",
    "    )\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.load(f\"{model_prefix}.model\")\n",
    "    print(f\"{model_prefix}: 실제 vocab size = {len(sp)}\")\n",
    "\n",
    "\n",
    "train_sentencepiece(\"eng_corpus.txt\", \"encoder_spm\", vocab_size)\n",
    "train_sentencepiece(\"kor_corpus.txt\", \"decoder_spm\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9B0hCWfS5zu",
    "outputId": "ec562ab8-173f-4bb7-dee3-67a84cfa63dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_tokenizer = spm.SentencePieceProcessor()\n",
    "encoder_tokenizer.load(\"encoder_spm.model\")\n",
    "\n",
    "decoder_tokenizer = spm.SentencePieceProcessor()\n",
    "decoder_tokenizer.load(\"decoder_spm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "n_-RrO9US50g",
    "outputId": "a6c07f66-3dba-48e0-e04e-1659b6c14660"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>kor</th>\n",
       "      <th>eng_proc</th>\n",
       "      <th>kor_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>가.</td>\n",
       "      <td>go .</td>\n",
       "      <td>가 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>안녕.</td>\n",
       "      <td>hi .</td>\n",
       "      <td>안녕 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>뛰어!</td>\n",
       "      <td>run !</td>\n",
       "      <td>뛰어 !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run.</td>\n",
       "      <td>뛰어.</td>\n",
       "      <td>run .</td>\n",
       "      <td>뛰어 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>누구?</td>\n",
       "      <td>who ?</td>\n",
       "      <td>누구 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6376</th>\n",
       "      <td>I started a new blog. I'll do my best not to b...</td>\n",
       "      <td>난 블로그를 시작했어. 블로그를 초반에만 반짝 많이 하다가 관두는 사람처럼은 되지 ...</td>\n",
       "      <td>i started a new blog . i'll do my best not to ...</td>\n",
       "      <td>난 블로그를 시작했어 . 블로그를 초반에만 반짝 많이 하다가 관두는 사람처럼은 되지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>I think it's a shame that some foreign languag...</td>\n",
       "      <td>몇몇 외국어 선생님이 한 번도 원어민과 공부해본 적도 없으면서 대학을 나올 수 있었...</td>\n",
       "      <td>i think it's a shame that some foreign languag...</td>\n",
       "      <td>몇몇 외국어 선생님이 한 번도 원어민과 공부해본 적도 없으면서 대학을 나올 수 있었...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6378</th>\n",
       "      <td>And the good news is that today the economy is...</td>\n",
       "      <td>다음으로 좋은 소식은 오늘 경제가 재성장한다는 것입니다. 임금, 소득, 집값, 퇴직...</td>\n",
       "      <td>and the good news is that today the economy is...</td>\n",
       "      <td>다음으로 좋은 소식은 오늘 경제가 재성장한다는 것입니다 . 임금 , 소득 , 집값 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6379</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>만일 네 사정도 잘 모르는 사람이 원어민 같다고 말한다면 그건 그 사람이 네가 원어...</td>\n",
       "      <td>if someone who doesn't know your background sa...</td>\n",
       "      <td>만일 네 사정도 잘 모르는 사람이 원어민 같다고 말한다면 그건 그 사람이 네가 원어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6380</th>\n",
       "      <td>Doubtless there exists in this world precisely...</td>\n",
       "      <td>의심의 여지 없이 세상에는 어떤 남자이든 정확히 딱 알맞는 여자와 결혼하거나 그 반...</td>\n",
       "      <td>doubtless there exists in this world precisely...</td>\n",
       "      <td>의심의 여지 없이 세상에는 어떤 남자이든 정확히 딱 알맞는 여자와 결혼하거나 그 반...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6381 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    eng  \\\n",
       "0                                                   Go.   \n",
       "1                                                   Hi.   \n",
       "2                                                  Run!   \n",
       "3                                                  Run.   \n",
       "4                                                  Who?   \n",
       "...                                                 ...   \n",
       "6376  I started a new blog. I'll do my best not to b...   \n",
       "6377  I think it's a shame that some foreign languag...   \n",
       "6378  And the good news is that today the economy is...   \n",
       "6379  If someone who doesn't know your background sa...   \n",
       "6380  Doubtless there exists in this world precisely...   \n",
       "\n",
       "                                                    kor  \\\n",
       "0                                                    가.   \n",
       "1                                                   안녕.   \n",
       "2                                                   뛰어!   \n",
       "3                                                   뛰어.   \n",
       "4                                                   누구?   \n",
       "...                                                 ...   \n",
       "6376  난 블로그를 시작했어. 블로그를 초반에만 반짝 많이 하다가 관두는 사람처럼은 되지 ...   \n",
       "6377  몇몇 외국어 선생님이 한 번도 원어민과 공부해본 적도 없으면서 대학을 나올 수 있었...   \n",
       "6378  다음으로 좋은 소식은 오늘 경제가 재성장한다는 것입니다. 임금, 소득, 집값, 퇴직...   \n",
       "6379  만일 네 사정도 잘 모르는 사람이 원어민 같다고 말한다면 그건 그 사람이 네가 원어...   \n",
       "6380  의심의 여지 없이 세상에는 어떤 남자이든 정확히 딱 알맞는 여자와 결혼하거나 그 반...   \n",
       "\n",
       "                                               eng_proc  \\\n",
       "0                                                  go .   \n",
       "1                                                  hi .   \n",
       "2                                                 run !   \n",
       "3                                                 run .   \n",
       "4                                                 who ?   \n",
       "...                                                 ...   \n",
       "6376  i started a new blog . i'll do my best not to ...   \n",
       "6377  i think it's a shame that some foreign languag...   \n",
       "6378  and the good news is that today the economy is...   \n",
       "6379  if someone who doesn't know your background sa...   \n",
       "6380  doubtless there exists in this world precisely...   \n",
       "\n",
       "                                               kor_proc  \n",
       "0                                                   가 .  \n",
       "1                                                  안녕 .  \n",
       "2                                                  뛰어 !  \n",
       "3                                                  뛰어 .  \n",
       "4                                                  누구 ?  \n",
       "...                                                 ...  \n",
       "6376  난 블로그를 시작했어 . 블로그를 초반에만 반짝 많이 하다가 관두는 사람처럼은 되지...  \n",
       "6377  몇몇 외국어 선생님이 한 번도 원어민과 공부해본 적도 없으면서 대학을 나올 수 있었...  \n",
       "6378  다음으로 좋은 소식은 오늘 경제가 재성장한다는 것입니다 . 임금 , 소득 , 집값 ...  \n",
       "6379  만일 네 사정도 잘 모르는 사람이 원어민 같다고 말한다면 그건 그 사람이 네가 원어...  \n",
       "6380  의심의 여지 없이 세상에는 어떤 남자이든 정확히 딱 알맞는 여자와 결혼하거나 그 반...  \n",
       "\n",
       "[6381 rows x 4 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WoFGMkSHS528",
    "outputId": "5e78eb4f-c042-4f18-aad8-5c9b69c832de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 인덱스: 6380\n",
      "ENG: doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman .\n",
      "KOR: 의심의 여지 없이 세상에는 어떤 남자이든 정확히 딱 알맞는 여자와 결혼하거나 그 반대의 상황이 존재하지 . 그런데 인간이 수백 명의 사람만 알고 지내는 사이가 될 기회를 갖는다고 생각해 보면 , 또 그 수백 명 중 열여 명 쯤 이하만 잘 알 수 있고 , 그리고 나서 그 열여 명 중에 한두 명만 친구가 될 수 있다면 , 그리고 또 만일 우리가 이 세상에 살고 있는 수백만 명의 사람들만 기억하고 있다면 , 딱 맞는 남자는 지구가 생겨난 이래로 딱 맞는 여자를 단 한번도 만난 적이 없을 수도 있을 거라는 사실을 쉽게 눈치챌 수 있을 거야 .\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_IDX = min(10000, len(df) - 1)\n",
    "eng_sample = df.loc[SAMPLE_IDX, \"eng_proc\"]\n",
    "kor_sample = df.loc[SAMPLE_IDX, \"kor_proc\"]\n",
    "print(f\"샘플 인덱스: {SAMPLE_IDX}\")\n",
    "print(\"ENG:\", eng_sample)\n",
    "print(\"KOR:\", kor_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnw3dS2ES55J",
    "outputId": "b24df2f1-807c-4e3a-f65a-94cc38bb3f16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1537,\n",
       " 574,\n",
       " 55,\n",
       " 743,\n",
       " 5,\n",
       " 27,\n",
       " 46,\n",
       " 5,\n",
       " 244,\n",
       " 135,\n",
       " 1757,\n",
       " 136,\n",
       " 42,\n",
       " 15,\n",
       " 8,\n",
       " 174,\n",
       " 129,\n",
       " 758,\n",
       " 53,\n",
       " 76,\n",
       " 226,\n",
       " 19,\n",
       " 125,\n",
       " 10,\n",
       " 1502,\n",
       " 21,\n",
       " 8,\n",
       " 74,\n",
       " 518,\n",
       " 139,\n",
       " 1266,\n",
       " 5,\n",
       " 87,\n",
       " 155,\n",
       " 127,\n",
       " 11,\n",
       " 1375,\n",
       " 20,\n",
       " 14,\n",
       " 312,\n",
       " 457,\n",
       " 66,\n",
       " 15,\n",
       " 623,\n",
       " 1558,\n",
       " 1281,\n",
       " 21,\n",
       " 36,\n",
       " 457,\n",
       " 968,\n",
       " 2012,\n",
       " 243,\n",
       " 373,\n",
       " 63,\n",
       " 59,\n",
       " 42,\n",
       " 14,\n",
       " 124,\n",
       " 362,\n",
       " 1005,\n",
       " 180,\n",
       " 8,\n",
       " 28,\n",
       " 8,\n",
       " 74,\n",
       " 130,\n",
       " 36,\n",
       " 15,\n",
       " 124,\n",
       " 362,\n",
       " 1005,\n",
       " 20,\n",
       " 55,\n",
       " 40,\n",
       " 155,\n",
       " 14,\n",
       " 1171,\n",
       " 19,\n",
       " 268,\n",
       " 848,\n",
       " 77,\n",
       " 24,\n",
       " 29,\n",
       " 49,\n",
       " 5,\n",
       " 27,\n",
       " 12,\n",
       " 1992,\n",
       " 42,\n",
       " 8,\n",
       " 28,\n",
       " 8,\n",
       " 74,\n",
       " 130,\n",
       " 36,\n",
       " 15,\n",
       " 1171,\n",
       " 19,\n",
       " 8,\n",
       " 28,\n",
       " 121,\n",
       " 268,\n",
       " 72,\n",
       " 301,\n",
       " 311,\n",
       " 71,\n",
       " 332,\n",
       " 8,\n",
       " 28,\n",
       " 31,\n",
       " 100,\n",
       " 8,\n",
       " 1235,\n",
       " 42,\n",
       " 26,\n",
       " 157,\n",
       " 19,\n",
       " 8,\n",
       " 28,\n",
       " 127,\n",
       " 38,\n",
       " 313,\n",
       " 15,\n",
       " 879,\n",
       " 36,\n",
       " 1661,\n",
       " 5,\n",
       " 77,\n",
       " 1749,\n",
       " 791,\n",
       " 46,\n",
       " 5,\n",
       " 244,\n",
       " 135,\n",
       " 8,\n",
       " 28,\n",
       " 20,\n",
       " 610,\n",
       " 733,\n",
       " 21,\n",
       " 8,\n",
       " 28,\n",
       " 826,\n",
       " 15,\n",
       " 658,\n",
       " 208,\n",
       " 32,\n",
       " 1434,\n",
       " 18,\n",
       " 8,\n",
       " 28,\n",
       " 15,\n",
       " 8,\n",
       " 174,\n",
       " 125,\n",
       " 66,\n",
       " 8,\n",
       " 137,\n",
       " 246,\n",
       " 12,\n",
       " 400,\n",
       " 15,\n",
       " 8,\n",
       " 174,\n",
       " 129,\n",
       " 758,\n",
       " 4,\n",
       " 2]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_token = encoder_tokenizer.encode(eng_sample)\n",
    "enc_token = [encoder_tokenizer.bos_id()] + enc_token + [encoder_tokenizer.eos_id()]\n",
    "enc_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "pr3_bJqNS57T",
    "outputId": "88c83ae2-50b2-4c3f-c50d-32286b96f09d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman .'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_decoding = encoder_tokenizer.decode(enc_token)\n",
    "enc_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "tbiewPHaS-wu"
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data, encoder_tokenizer, decoder_tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.encoder_tokenizer = encoder_tokenizer\n",
    "        self.decoder_tokenizer = decoder_tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pad_id = 0\n",
    "        self.bos_id = 1\n",
    "        self.eos_id = 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.data.iloc[idx]['eng_proc']\n",
    "        trg_text = self.data.iloc[idx]['kor_proc']\n",
    "\n",
    "        src_ids = self.encoder_tokenizer.encode(src_text)\n",
    "        trg_ids = self.decoder_tokenizer.encode(trg_text)\n",
    "\n",
    "        src_ids = src_ids[:self.max_len]\n",
    "\n",
    "        trg_input = [self.bos_id] + trg_ids[:self.max_len - 2] + [self.eos_id]\n",
    "        trg_label = trg_ids[:self.max_len - 1] + [self.eos_id]\n",
    "\n",
    "        src_ids = src_ids + [self.pad_id] * (self.max_len - len(src_ids))\n",
    "        trg_input = trg_input + [self.pad_id] * (self.max_len - len(trg_input))\n",
    "        trg_label = trg_label + [self.pad_id] * (self.max_len - len(trg_label))\n",
    "\n",
    "        return torch.tensor(src_ids), torch.tensor(trg_input), torch.tensor(trg_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "dDRx9O7tS-x_"
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "MAX_LEN = int(globals().get(\"MAX_SEQ_LEN\", 40))\n",
    "BATCH_SIZE = 1024  # 성능 최적화: 64 → 1024\n",
    "\n",
    "train_data = df.sample(frac=train_ratio, random_state=42)\n",
    "valid_data = df.drop(train_data.index)\n",
    "\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "valid_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_data = TranslationDataset(train_data, encoder_tokenizer, decoder_tokenizer, max_len=MAX_LEN)\n",
    "validataion_data = TranslationDataset(valid_data, encoder_tokenizer, decoder_tokenizer, max_len=MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "validation_loader = DataLoader(\n",
    "    validataion_data, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1O3NphcIS-0j",
    "outputId": "27e2bc5b-b81b-439d-9e65-72b112b036ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 25]) torch.Size([1024, 25]) torch.Size([1024, 25])\n"
     ]
    }
   ],
   "source": [
    "for src, trg_input, trg_label in train_loader:\n",
    "    print(src.shape, trg_input.shape, trg_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "Bk3JAHjCS-2n"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: (batch_size, hidden_dim)\n",
    "        # encoder_outputs: (src_len, batch_size, hidden_dim)\n",
    "\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)  # (batch_size, src_len, hidden_dim)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)  # (batch_size, src_len, hidden_dim)\n",
    "\n",
    "        energy = torch.tanh(self.W1(encoder_outputs) + self.W2(hidden))  # (batch_size, src_len, hidden_dim)\n",
    "        attention = self.v(energy).squeeze(2)  # (batch_size, src_len)\n",
    "\n",
    "        return nn.functional.softmax(attention, dim=1)  # (batch_size, src_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "7pREWdeUS-4q"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src : (src_len, batch_size)\n",
    "        embedded = self.embedding(src)  # embedded : (src_len, batch_size, emb_dim)\n",
    "        outputs, hidden = self.rnn(embedded)  # outputs : (src_len, batch_size, hidden_dim)\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "7tTuM69UUAcc"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, attention):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        # Decoder RNN에는 embedding만 입력\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim)\n",
    "        # 출력층에는 hidden state와 attention value가 결합되어 입력\n",
    "        self.fc_out = nn.Linear(hidden_dim + hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input : (batch_size,)\n",
    "        # hidden : (batch_size, hidden_dim)\n",
    "        # encoder_outputs : (src_len, batch_size, hidden_dim)\n",
    "        input = input.unsqueeze(0)  # input : (1, batch_size)\n",
    "        embedded = self.embedding(input)  # embedded : (1, batch_size, emb_dim)\n",
    "\n",
    "        # attention distribution을 계산합니다. decoder의 이전 hidden state, s_{t-1}와 encoder의 H가 입력됩니다.\n",
    "        a = self.attention(hidden[-1], encoder_outputs)  # a : (batch_size, src_len)\n",
    "\n",
    "        # H에 가중치를 부여해 attention value(Context vector) 계산\n",
    "        a = a.unsqueeze(1)  # a : (batch_size, 1, src_len)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)  # encoder_outputs : (batch_size, src_len, hidden_dim)\n",
    "        context = torch.bmm(a, encoder_outputs)  # context : (batch_size, 1, hidden_dim)\n",
    "        context = context.permute(1, 0, 2)  # context : (1, batch_size, hidden_dim)\n",
    "\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "\n",
    "        # 출력층에서는 현재 hidden state와 context vector를 결합하여 예측값 생성\n",
    "        output = output.squeeze(0)  # output : (batch_size, hidden_dim)\n",
    "        context = context.squeeze(0)  # context : (batch_size, hidden_dim)\n",
    "        prediction = self.fc_out(torch.cat((output, context), dim=1))  # (batch_size, output_dim)\n",
    "\n",
    "        return prediction, hidden, a.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "NwKdccFpUAfA"
   },
   "outputs": [],
   "source": [
    "class Seq2SeqAttention(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg=None, max_len=30, bos_id = 1, eos_id=2):\n",
    "        # 학습 모드에서는 trg_len 사용, 추론 모드에서는 max_len까지 동적 생성\n",
    "        batch_size = src.shape[1]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        # 조기 종료를 위해 tensor가 아닌 리스트 사용\n",
    "        outputs = []\n",
    "\n",
    "        # 시각화를 위해 attention 저장\n",
    "        attentions = []\n",
    "\n",
    "        # 인코더를 통해 context 생성\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        if trg is not None:\n",
    "            for t in range(0, trg.shape[0]):\n",
    "                input = trg[t]\n",
    "                output, hidden, attention = self.decoder(input, hidden, encoder_outputs)\n",
    "                outputs.append(output.unsqueeze(0))\n",
    "                attentions.append(attention.unsqueeze(0))\n",
    "\n",
    "        else:\n",
    "\t\t    # inference에서는 target(정답)이 없기 때문에 sos_token을 생성해줍니다.\n",
    "            input = torch.full((batch_size,), bos_id, dtype=torch.long, device=self.device)\n",
    "            finished = torch.zeros(batch_size, dtype=torch.bool, device=self.device)\n",
    "\n",
    "            for t in range(max_len):\n",
    "                output, hidden, attention = self.decoder(input, hidden,  encoder_outputs)\n",
    "                outputs.append(output.unsqueeze(0))\n",
    "                attentions.append(attention.unsqueeze(0))\n",
    "                top1 = output.argmax(1)\n",
    "                input = top1\n",
    "\n",
    "                # 조기 종료 조건\n",
    "                finished |= (top1 == eos_id)\n",
    "                if finished.all():\n",
    "                    break\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=0)  # (trg_len, batch_size, output_dim)\n",
    "        attentions = torch.cat(attentions, dim=0)  # (trg_len, batch_size, src_len)\n",
    "\n",
    "        return outputs, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "c8iHgvZ2UAhG"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "input_dim = len(encoder_tokenizer)\n",
    "output_dim = len(decoder_tokenizer)\n",
    "emb_dim = 256\n",
    "hid_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "6DQWZTDfUAjH"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim, emb_dim, hid_dim).to(device)\n",
    "attention = BahdanauAttention(hid_dim).to(device)\n",
    "decoder = Decoder(output_dim, emb_dim, hid_dim, attention).to(device)\n",
    "model = Seq2SeqAttention(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQURBFDiUEWo",
    "outputId": "5798ceea-63f2-4496-d790-4f3dd16432ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqAttention(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(2396, 256)\n",
      "    (rnn): GRU(256, 512)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention): BahdanauAttention(\n",
      "      (W1): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (W2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
      "    )\n",
      "    (embedding): Embedding(3000, 256)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (fc_out): Linear(in_features=1024, out_features=3000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf8sXRtxUIWr",
    "outputId": "8072cc77-ba5c-4104-d26c-2d2c3d48cc6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOzQeqKoUIX6",
    "outputId": "49876463-b06b-471f-9ba2-ef1d79379ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "def train_step(model, data_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch+1}\", leave=True)\n",
    "\n",
    "    for src, trg_input, trg_label in progress_bar:\n",
    "        # ✅ 차원 변환: (batch, seq) → (seq, batch)\n",
    "        src = src.transpose(0, 1).to(device)\n",
    "        trg_input = trg_input.transpose(0, 1).to(device)\n",
    "        trg_label = trg_label.transpose(0, 1).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs,_ = model(src, trg_input)\n",
    "\n",
    "        # (trg_len, batch_size, output_dim)을 (batch_size * trg_len, output_dim)으로 변환\n",
    "        outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "        trg_label = trg_label.reshape(-1)\n",
    "\n",
    "        loss = criterion(outputs, trg_label)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "print(\"슝~\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTaGaTT5UIZ-",
    "outputId": "27ea35c4-12b9-4daf-f2dc-c508611500eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 5/5 [00:00<00:00,  8.53it/s, loss=5.93]\n",
      "Epoch 1: 100%|██████████| 5/5 [00:00<00:00,  8.53it/s, loss=5.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 7.0759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 5/5 [00:00<00:00, 10.19it/s, loss=5.25]\n",
      "Epoch 2: 100%|██████████| 5/5 [00:00<00:00, 10.19it/s, loss=5.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 5.4221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 10.75it/s, loss=5]   \n",
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 10.75it/s, loss=5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 5.0559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00,  9.96it/s, loss=4.8] \n",
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00,  9.96it/s, loss=4.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 4.8338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5/5 [00:00<00:00, 10.04it/s, loss=4.56]\n",
      "Epoch 5: 100%|██████████| 5/5 [00:00<00:00, 10.04it/s, loss=4.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 4.6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 5/5 [00:00<00:00, 10.08it/s, loss=4.38]\n",
      "Epoch 6: 100%|██████████| 5/5 [00:00<00:00, 10.08it/s, loss=4.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 4.4249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 5/5 [00:00<00:00, 10.10it/s, loss=4.2] \n",
      "Epoch 7: 100%|██████████| 5/5 [00:00<00:00, 10.10it/s, loss=4.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 4.2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 5/5 [00:00<00:00, 10.13it/s, loss=4.04]\n",
      "Epoch 8: 100%|██████████| 5/5 [00:00<00:00, 10.13it/s, loss=4.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 4.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 10.06it/s, loss=3.82]\n",
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 10.06it/s, loss=3.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 3.8782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 5/5 [00:00<00:00, 10.12it/s, loss=3.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 3.7111\n",
      "CPU times: user 4.06 s, sys: 265 ms, total: 4.33 s\n",
      "Wall time: 5.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_step(model, train_loader, optimizer, criterion, epoch)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Train Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sX8_0sOEUIcU",
    "outputId": "b1eeb5a7-cdd9-40e7-c6d1-63b2d31be02c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "source": [
    "def eval_step(model, data_loader, optimizer, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    for src, trg_input, trg_label in data_loader:\n",
    "        # ✅ 차원 변환: (batch, seq) → (seq, batch)\n",
    "        src = src.transpose(0, 1).to(device)\n",
    "        trg_input = trg_input.transpose(0, 1).to(device)\n",
    "        trg_label = trg_label.transpose(0, 1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs, _ = model(src, trg_input)\n",
    "\n",
    "        # (trg_len, batch_size, output_dim)을 (batch_size * trg_len, output_dim)으로 변환\n",
    "        outputs = outputs.reshape(-1, outputs.shape[-1])\n",
    "        trg_label = trg_label.reshape(-1)\n",
    "\n",
    "        loss = criterion(outputs, trg_label)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "print(\"슝~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vv9XmWH7UIej",
    "outputId": "6c4217aa-1553-40b7-9604-37a49a8438a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 5/5 [00:00<00:00, 10.14it/s, loss=3.51]\n",
      "Epoch 1: 100%|██████████| 5/5 [00:00<00:00, 10.14it/s, loss=3.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 3.5497, Validation Loss: 4.3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 5/5 [00:00<00:00,  7.87it/s, loss=3.37]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 3.3936, Validation Loss: 4.2373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00,  9.67it/s, loss=3.21]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 3.2414, Validation Loss: 4.1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 10.12it/s, loss=3.09]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 3.0926, Validation Loss: 4.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5/5 [00:00<00:00, 10.18it/s, loss=2.92]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Loss: 2.9497, Validation Loss: 4.0746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 5/5 [00:00<00:00, 10.10it/s, loss=2.77]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Train Loss: 2.8068, Validation Loss: 4.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 5/5 [00:00<00:00, 10.15it/s, loss=2.66]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Train Loss: 2.6678, Validation Loss: 3.9834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 5/5 [00:00<00:00, 10.11it/s, loss=2.48]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Loss: 2.5333, Validation Loss: 3.9487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 10.21it/s, loss=2.38]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Train Loss: 2.3987, Validation Loss: 3.9176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 5/5 [00:00<00:00, 10.21it/s, loss=2.25]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Train Loss: 2.2684, Validation Loss: 3.8845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 5/5 [00:00<00:00, 10.24it/s, loss=2.11]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Train Loss: 2.1420, Validation Loss: 3.8709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 5/5 [00:00<00:00, 10.25it/s, loss=2.01]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Train Loss: 2.0185, Validation Loss: 3.8356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 5/5 [00:00<00:00, 10.20it/s, loss=1.9] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Train Loss: 1.8970, Validation Loss: 3.8156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 5/5 [00:00<00:00, 11.09it/s, loss=1.75]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Train Loss: 1.7783, Validation Loss: 3.7972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 5/5 [00:00<00:00, 11.22it/s, loss=1.63]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Train Loss: 1.6645, Validation Loss: 3.7876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 5/5 [00:00<00:00, 11.22it/s, loss=1.55]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Train Loss: 1.5535, Validation Loss: 3.7728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 5/5 [00:00<00:00, 10.84it/s, loss=1.45]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Train Loss: 1.4475, Validation Loss: 3.7584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 5/5 [00:00<00:00, 11.03it/s, loss=1.31]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Train Loss: 1.3444, Validation Loss: 3.7482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 5/5 [00:00<00:00, 11.25it/s, loss=1.26]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Train Loss: 1.2470, Validation Loss: 3.7419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 5/5 [00:00<00:00, 10.01it/s, loss=1.15]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 1.1536, Validation Loss: 3.7349\n",
      "CPU times: user 9.02 s, sys: 922 ms, total: 9.94 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_step(model, train_loader, optimizer, criterion, epoch)\n",
    "    valid_loss = eval_step(model, validation_loader, optimizer, criterion)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "8iahDqraUIgj"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, model, encoder_tokenizer, decoder_tokenizer, max_len=30):\n",
    "    model.eval()\n",
    "\n",
    "    sentence = preprocess_text(sentence)\n",
    "    src_ids = encoder_tokenizer.encode(sentence)\n",
    "    src_ids = src_ids[:max_len]\n",
    "    src_ids = src_ids + [0] * (max_len - len(src_ids))\n",
    "    src_tensor = torch.tensor(src_ids).unsqueeze(1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs, attentions = model(src_tensor, max_len=max_len)\n",
    "\n",
    "    pred_ids = outputs.argmax(2).squeeze(1).tolist()\n",
    "    eos_token = decoder_tokenizer.eos_id()\n",
    "    if eos_token in pred_ids:\n",
    "        pred_ids = pred_ids[:pred_ids.index(eos_token)]\n",
    "\n",
    "    result = decoder_tokenizer.decode(pred_ids).replace('▁', ' ').strip()\n",
    "\n",
    "    return result, sentence, attentions.squeeze(1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "iiwnk406UIij"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticks(range(len(sentence)))\n",
    "    ax.set_xticklabels(sentence, fontdict=fontdict, rotation=90)\n",
    "\n",
    "    ax.set_yticks(range(len(predicted_sentence)))\n",
    "    ax.set_yticklabels(predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "ZReRL_46UPrq"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, model, encoder_tokenizer, decoder_tokenizer, max_len=30):\n",
    "    result, sentence, attention = evaluate(sentence, model, encoder_tokenizer, decoder_tokenizer, max_len)\n",
    "\n",
    "    print(f'Input (ENG): {sentence}')\n",
    "    print(f'Predicted translation (KOR): {result}')\n",
    "\n",
    "    src_tokens = sentence.split()\n",
    "    trg_tokens = result.split()\n",
    "    attention = attention[:len(trg_tokens), :len(src_tokens)]\n",
    "\n",
    "    if len(src_tokens) and len(trg_tokens):\n",
    "        plot_attention(attention, src_tokens, trg_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "yqDCUixGUSoW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (ENG): may i help you ?\n",
      "Predicted translation (KOR): 제가 도와드릴까요 ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51228 (\\N{HANGUL SYLLABLE JE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50752 (\\N{HANGUL SYLLABLE WA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 46300 (\\N{HANGUL SYLLABLE DEU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47540 (\\N{HANGUL SYLLABLE RIL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44620 (\\N{HANGUL SYLLABLE GGA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50836 (\\N{HANGUL SYLLABLE YO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"May I help you?\", model, encoder_tokenizer, decoder_tokenizer, max_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (ENG): there is a cat\n",
      "Predicted translation (KOR): 멋져가 있어요 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47691 (\\N{HANGUL SYLLABLE MEOS}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51256 (\\N{HANGUL SYLLABLE JYEO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51080 (\\N{HANGUL SYLLABLE ISS}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50612 (\\N{HANGUL SYLLABLE EO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50836 (\\N{HANGUL SYLLABLE YO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"There is a cat\", model, encoder_tokenizer, decoder_tokenizer, max_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "dEISom-6UTql"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (ENG): can i have some coffee ?\n",
      "Predicted translation (KOR): 커피 한 잔 더 마시겠습니까 ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 52964 (\\N{HANGUL SYLLABLE KEO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54588 (\\N{HANGUL SYLLABLE PI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54620 (\\N{HANGUL SYLLABLE HAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51092 (\\N{HANGUL SYLLABLE JAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45908 (\\N{HANGUL SYLLABLE DEO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47560 (\\N{HANGUL SYLLABLE MA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49884 (\\N{HANGUL SYLLABLE SI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44192 (\\N{HANGUL SYLLABLE GESS}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49845 (\\N{HANGUL SYLLABLE SEUB}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45768 (\\N{HANGUL SYLLABLE NI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/venv/main/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44620 (\\N{HANGUL SYLLABLE GGA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 실행 예제\n",
    "translate(\"Can I have some coffee?\", model, encoder_tokenizer, decoder_tokenizer, max_len=30)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
